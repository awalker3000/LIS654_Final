<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE = edge">
  <meta name="viewport" content="width = device-width, initial-scale = 1">
  <title>Web Archiving for Art History</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css" />
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
</head>

<body>
  <div class="jumbotron">
    <div class="container">
      <h1>Archiving Digital Art Resources</h1>
      <p>Web Archiving and Art History</p>
    </div>
  </div>
  <nav class="navbar navbar-expand-md bg-dark navbar-dark">
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsibleNavbar">
    <span class="navbar-toggler-icon"></span>
  </button>
    <div class="collapse navbar-collapse" id="collapsibleNavbar">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="whyArchive.html">Why Archive?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="projects.html">Projects</a>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbardrop" data-toggle="dropdown">
        Try it yourself
        </a>
          <div class="dropdown-menu bg-dark">
            <a class="dropdown-item" href="planning.html">Project Planning</a>
            <a class="dropdown-item" href="process.html">Process of Archiving a Website</a>
            <a class="dropdown-item" href="tools.html">Experiments with Archiving Tools</a>
          </div>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="archivability.html">Improving Website Archivability</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="aboutUs.html">About Us</a>
        </li>
      </ul>
    </div>
  </nav>
  <div class="container">
    <h2>Process of Archiving a Website</h2>
    <h6><em>Abigail Walker</em></h6>
  </div>
  <br>
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <p>Though the process is evolving with emerging technology and differs depending on the tools used, the steps taken to archive a website are fairly consistent. You may not see all these steps in action if you’re using a browser plugin, for example,
          but knowing what’s going on will lead to a deeper understanding of the process. This in turn will lead to <a href="tools.html">better selection of tools</a>, and will make it easier for you to provide access and reference to those wanting to
          see what you’ve saved.</p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-12"><hr class="pink">
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <div class="text-center">
          <img src="identify.png" class="figure-img img-fluid" alt="Magnifying glass">
        </div>
      </div>
      <div class="col-md-8">
        <h3>Identify</h3>
        <p>The first step is to find what it is you want to save, and how often. When you archive websites, you are building a collection, and having a website collection development policy or an addendum to your current policy can help you sort through
          the vast amount of art-related content on the web.</p>
        <p>Check out our <a href="projects.html">projects profiles</a> and our <a href="planning.html">project planning page</a> for collection development inspiration, advice, and considerations.</p>
        <p>While you are considering which websites to collect, it is important to keep in mind the technical limits of web archiving.
          Though progress is being made, certain features of websites are still challenging to capture. This includes:</p>
        <ul>
          <li>Dynamic or interactive content, such as elements created with Flash or Javascript</li>
          <li>Streaming video and audio files</li>
          <li>Password-protected, un-indexed, and other "unfindable" content</li>
          <li>Social media and other database-driven websites</li>
        </ul>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
      </div>
      <div class="col-md-8">
        <div class="text-center">
          <img src="prattfb.png" class="figure-img img-responsive img-thumbnail img-fluid" alt="Screenshot of an archived version of Pratt Institute's Facebook page">
          <figcaption class="figure-caption">An unsucessful capture of Pratt Institute's Facebook page in the Internet Archive</figcaption>
          <br><br>
        </div>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-12"><hr class="pink">
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <div class="text-center">
          <img src="acquire.png" class="figure-img img-fluid" alt="Spider">
        </div>
      </div>
      <div class="col-md-8">
        <h3>Acquire</h3>
        <p>Once you have websites in mind, you can start capturing all the data needed to successfully rebuild a versions of them from a particular points in time. You will need to acquire all of the code (HTML, CSS, Javascript, etc.) used to build the website,
          plus images, audio and video files, and any other files essential for recreation.</p>
        <p>To do this, you can deploy a web crawler or spider. Crawlers are automated programs or scripts that browse the internet and harvest information from websites for various purposes. They aren’t just useful for web archivists - crawlers are used
          by search engines to systematically index the web, and can be used for tasks such as checking the validity of links on a website.</p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
      </div>
      <div class="col-md-4 vertical-center">
        <div class="text-center">
          <img src="robot_icon.png" class="figure-img img-fluid" alt="Robot">
        </div>
      </div>
      <div class="col-md-4">
        <p><a name="robots">If a webmaster wants to block web crawlers from accessing and indexing certain parts or all of their website, they can include <a href="http://www.robotstxt.org/" target="_blank">robots.txt</a>, a file that tells the crawler what to ignore. This
          can cause difficulties for web archivists wanting to save these sites. However, as it operates on the honor system, the file can be worked around. Either by contact the webmaster and ask that they allow your crawler in, or prompt the crawler to “ignore robots.txt”.</a></p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
      </div>
      <div class="col-md-8">
        <p>In the web archiving world, the most widely used crawler is <a href="https://webarchive.jira.com/wiki/spaces/Heritrix/overview" target="_blank">Heritrix</a>.
          It was built by the Internet Archive, and is open-source and extensible.
          However, it isn’t always able to capture audio and video files and other dynamic content.
          To combat this, the Internet Archive is now developing <a href="https://github.com/internetarchive/brozzler" target="_blank">brozzler</a>, which uses a browser to load pages, and works in conjunction with <a href="https://github.com/rg3/youtube-dl" target="_blank">youtube-dl</a> to download and capture these files.
          Open-source crawlers are also being developed by individuals, and many of these tools utilize a browser in the same manner as brozzler.</p>

        <p>Archiving services like <a href="https://webrecorder.io/" target="_blank">Webrecorder</a> don’t utilize crawlers, and instead record your network traffic as you navigate through a website as a way of discovering URLs.</p>
        <p>For each website, you'll start with a URL or <strong>seed</strong> that serves as the crawler's entry point. In addition to this starting point, you will also need to establish your <strong>scope</strong>, or the extent of what you’d like to capture.</p>
        <p>Websites often contain vast amounts of links, which can turn into prohibitive amounts of data. This can be both cumbersome to acquire and access, as well as expensive to store. Other elements, such as event calendars, can cause your crawler
          to crawl infinitely into the future. You can avoid these crawler traps and other difficulties by:</p>
        <ul>
          <li>Limiting your scope to certain pages of a site by specifically setting those URLs as seeds</li>
          <li>Giving your crawl a data or time limit</li>
          <li>Giving your crawl a small depth - the depth is the number of links away from the main seed that the crawler will capture.
            If every piece of the website you want is one link away from the main seed, you can give your crawl a depth of one, and so on</li>
        </ul>
        <p>After the crawler has finished gathering the data within your scope, it will deliver it to you in a standardized way, most likely as a <a href="http://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.0/" target="_blank">Web ARChive (WARC)</a> or <a href="https://www.loc.gov/preservation/digital/formats/fdd/fdd000235.shtml" target="_blank">ARC</a> file.</p>
          <p>An ARC format file consists of a one-line header describing what was captured in the crawl, followed by all of the harvested data in one block.
            It is the original file format for archiving websites, used since 1996 by the Internet Archive to manage their website captures and other digital objects.</p>
          <p>The WARC file format is an extension of ARC, and what you’re most likely to run into if you’re starting to archive today and don’t have any legacy data.
            It provides more structure to the data gleaned from the site itself, and includes more secondary content, including assigned metadata and more information about the capture.</p>
            <img src="warc.png" class="figure-img img-responsive img-thumbnail img-fluid" alt="An example of a WARC file">
            <p>When you look at a WARC file, you can see the header, followed by the payload - all code, images, and documents from a website in the form of raw data, together in one long string.</p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-12"><hr class="pink">
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <div class="text-center">
          <img src="store.png" class="figure-img img-fluid" alt="Server">
        </div>
      </div>
      <div class="col-md-8">
        <h3>Store</h3>
  <p>Your archived data can be stored as WARC or ARC files.
    If your files are being stored by you rather than a third party, it is imperative to follow best practices for data management to avoid data loss.
    The 3-2-1 backup plan is a common strategy for data storage.</p>
<p>Try to have<br><br>
<strong>3</strong> copies of your data on<br><br>
<strong>2</strong> different types of devices or storage media with<br><br>
<strong>1</strong> copy stored offsite<br><br>
The amount of storage space necessary for each capture may vary wildly based on scope and the amount of data present on each website.</p>
</div>
</div>
</div>
<div class="container">
  <div class="row">
    <div class="col-md-12"><hr class="pink">
    </div>
  </div>
</div>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <div class="text-center">
          <img src="enable.png" class="figure-img img-fluid" alt="Hands and a light bulb">
        </div>
      </div>
      <div class="col-md-8">
        <h3>Enable access</h3>
        <p>All of the hard work you put into archiving endangered art historical web content will pay off once you provide access to the sites you’ve archived.</p>
        <p>WARC files can be viewed and interacted with through web players.
          The most widely used player, the <a href="http://archive.org/web/" target="_blank">Wayback Machine</a>, is also a product of the Internet Archive.</p>
          <p>You can provide patrons with a link to your file through the players, many of which display the site along with technical metadata about the capture itself, such as the date, time, and who initiated the crawl.
          There are many ways institutions have provided additional metadata about their captures and connected patrons to them through their website or catalog.</p>
          <ul>
            <li>The Library of Congress lists archived sites under their <a href="https://www.loc.gov/collections/" target="_blank">digital collections</a>, and includes automatically generated and cataloger enhanced MODSXML records with each archived site</li>
            <li>NYU's Tamiment Library creates simple <a href="http://dlib.nyu.edu/findingaids/html/tamwag/web_arc_001/dsc.html" target="_blank">finding aids</a> using DACS for each of their archived websites, including a title, short description, subjects, and a link to the Wayback Machine</li>
            <li>One could even create a MARC record for each site as you would for any other electronic resource</li>
          </ul>
          <p>For institutions using Archive-It, patrons can most easily access collections through the <a href="https://archive-it.org/explore?show=Collections" target="_blank">Archive-It website</a>.
            Archive-It adds an interface on top of the Wayback Machine where each collection and set of captures is described and linked to.
            The captures can be tagged with searchable <a href="https://support.archive-it.org/hc/en-us/articles/208332603-Add-edit-and-manage-your-metadata" target="_blank">Dublin Core</a> fields, or patrons can search the full text of websites.</p>
      </div>
    </div>
  </div>
</body>

<footer>
    <div class="footer">
    <p class="by">©2018 Chelsea Cates & Abigail Walker</p>
    </div>
</footer>

</html>
